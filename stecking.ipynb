{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nimport scipy.special\n\nfrom catboost import CatBoostClassifier, Pool\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =====================\n# CONFIG\n# =====================\nDATA_PATH = \"/kaggle/input/playground-series-s4e8/\"\nN_SPLITS = 5\nSEED = 42\nTHRESHOLD = 0.5\nTARGET = \"class\"\nUSE_GPU = True\nLABEL_SMOOTH = 0.05\n\n# Важно: на этом соревновании сильнее всего работает ансамблирование и OOF-порог.\nMODEL_SPECS = [\n    {\"seed\": 1,  \"params\": dict(depth=8, l2_leaf_reg=6.0, random_strength=1.0, bagging_temperature=0.8)},\n    {\"seed\": 7,  \"params\": dict(depth=9, l2_leaf_reg=10.0, random_strength=2.0, bagging_temperature=0.6)},\n    {\"seed\": 42, \"params\": dict(depth=7, l2_leaf_reg=4.0, random_strength=1.5, bagging_temperature=1.0)},\n]\n\n# “джиттер” только на реальных numeric\nJITTER_STRENGTH = 0.01\n\n# сколько бинов для числовых (обычно 32-64 норм)\nN_BINS = 48\n\n# rare threshold для категорий (уменьшаем кардинальность)\nRARE_MIN_COUNT = 50\n\n# немного “хэширующих” кроссов, но БЕЗ строк (экономим память)\nMAX_HASHED_CROSSES = 8\n\n\n# =====================\n# LOAD\n# =====================\ntrain = pd.read_csv(DATA_PATH + \"train.csv\")\ntest  = pd.read_csv(DATA_PATH + \"test.csv\")\n\ny = (train[\"class\"] == \"p\").astype(np.int8)\ntrain_ids = train[\"id\"].values\ntest_ids  = test[\"id\"].values\n\nX = train.drop(columns=[\"class\", \"id\"])\nX_test = test.drop(columns=[\"id\"])\n\n# =====================\n# PREPROCESS + FE\n# =====================\ndef replace_question_marks(df, cat_cols):\n    df = df.copy()\n    for c in cat_cols:\n        df[c] = df[c].replace(\"?\", np.nan)\n    return df\n\ndef add_missing_flags_and_fill(df, cat_cols):\n    df = df.copy()\n    # флаги пропусков\n    for c in cat_cols:\n        df[c + \"__isna\"] = df[c].isna().astype(np.int8)\n        df[c] = df[c].fillna(\"missing\").astype(\"string\")\n    # общий счётчик пропусков (по исходным cat)\n    df[\"missing_count\"] = df[[c + \"__isna\" for c in cat_cols]].sum(axis=1).astype(np.int16)\n    return df\n\ndef group_rare_categories(train_df, test_df, cat_cols, min_count=50):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    for c in cat_cols:\n        vc = train_df[c].value_counts(dropna=False)\n        rare_vals = set(vc[vc < min_count].index.tolist())\n        # rare в train\n        train_df[c] = train_df[c].where(~train_df[c].isin(rare_vals), \"rare\")\n        # unseen/rare в test\n        seen_vals = set(vc.index.tolist())\n        test_df[c] = test_df[c].where(test_df[c].isin(seen_vals), \"unseen\")\n        test_df[c] = test_df[c].where(~test_df[c].isin(rare_vals), \"rare\")\n    return train_df, test_df\n\ndef add_freq_enc(train_df, test_df, cat_cols):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    n = len(train_df)\n    for c in cat_cols:\n        vc = train_df[c].value_counts(dropna=False)\n        train_df[c + \"__freq\"] = train_df[c].map(vc).fillna(0).astype(np.float32)\n        test_df[c + \"__freq\"]  = test_df[c].map(vc).fillna(0).astype(np.float32)\n\n        train_df[c + \"__freq_norm\"] = (train_df[c + \"__freq\"] / n).astype(np.float32)\n        test_df[c + \"__freq_norm\"]  = (test_df[c + \"__freq\"] / n).astype(np.float32)\n\n        train_df[c + \"__logcnt\"] = np.log1p(train_df[c + \"__freq\"]).astype(np.float32)\n        test_df[c + \"__logcnt\"]  = np.log1p(test_df[c + \"__freq\"]).astype(np.float32)\n    return train_df, test_df\n\ndef add_numeric_bins(train_df, test_df, num_cols, n_bins=48):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    for c in num_cols:\n        # квантили по train\n        qs = np.quantile(train_df[c].values, np.linspace(0, 1, n_bins + 1))\n        qs = np.unique(qs)\n        # если мало уникальных — пропускаем биннинг\n        if len(qs) <= 3:\n            continue\n        # digitize: 0..(len(qs)-2)\n        cut_points = qs[1:-1]\n        train_df[c + \"__bin\"] = np.digitize(train_df[c].values, cut_points, right=True).astype(np.int16)\n        test_df[c + \"__bin\"]  = np.digitize(test_df[c].values,  cut_points, right=True).astype(np.int16)\n    return train_df, test_df\n\ndef add_numeric_transforms(train_df, test_df, num_cols):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    for c in num_cols:\n        # безопасный log1p (на случай нулей)\n        train_df[c + \"__log1p\"] = np.log1p(np.maximum(train_df[c].values, 0)).astype(np.float32)\n        test_df[c + \"__log1p\"]  = np.log1p(np.maximum(test_df[c].values,  0)).astype(np.float32)\n\n    # типичные взаимодействия для грибов (если такие колонки есть)\n    def has(col): return col in train_df.columns\n    if has(\"stem-height\") and has(\"stem-width\"):\n        train_df[\"stem_hw\"] = (train_df[\"stem-height\"] * train_df[\"stem-width\"]).astype(np.float32)\n        test_df[\"stem_hw\"]  = (test_df[\"stem-height\"]  * test_df[\"stem-width\"]).astype(np.float32)\n\n        train_df[\"stem_h_div_w\"] = (train_df[\"stem-height\"] / (train_df[\"stem-width\"] + 1e-6)).astype(np.float32)\n        test_df[\"stem_h_div_w\"]  = (test_df[\"stem-height\"]  / (test_df[\"stem-width\"]  + 1e-6)).astype(np.float32)\n\n    if has(\"cap-diameter\") and has(\"stem-height\"):\n        train_df[\"cap_div_stem_h\"] = (train_df[\"cap-diameter\"] / (train_df[\"stem-height\"] + 1e-6)).astype(np.float32)\n        test_df[\"cap_div_stem_h\"]  = (test_df[\"cap-diameter\"]  / (test_df[\"stem-height\"]  + 1e-6)).astype(np.float32)\n\n    return train_df, test_df\n\ndef add_hashed_crosses(train_df, test_df, cat_cols, max_pairs=8):\n    \"\"\"\n    Делает “комбо”-фичи, но без строк:\n    хэш от пары значений -> int64, и мы скажем CatBoost, что это categorical.\n    \"\"\"\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n\n    # берём умеренно низкокардинальные колонки, чтобы пары были осмысленными\n    nun = train_df[cat_cols].nunique()\n    chosen = nun.sort_values().index.tolist()[:10]  # топ-10 по низкой кардинальности\n    pairs = []\n    for i in range(len(chosen)):\n        for j in range(i+1, len(chosen)):\n            pairs.append((chosen[i], chosen[j]))\n    pairs = pairs[:max_pairs]\n\n    for a, b in pairs:\n        name = f\"{a}__X__{b}\"\n        train_df[name] = pd.util.hash_pandas_object(train_df[[a, b]], index=False).astype(np.int64)\n        test_df[name]  = pd.util.hash_pandas_object(test_df[[a, b]],  index=False).astype(np.int64)\n\n    return train_df, test_df\n\n# --- определяем исходные типы\ncat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\nnum_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n\n# 1) ? -> NaN\nX = replace_question_marks(X, cat_cols)\nX_test = replace_question_marks(X_test, cat_cols)\n\n# 2) numeric: median impute (сразу, чтобы дальше bins/трансформы работали)\nfor c in num_cols:\n    med = X[c].median()\n    X[c] = X[c].fillna(med)\n    X_test[c] = X_test[c].fillna(med)\n\n# 3) missing flags + fill cats\nX = add_missing_flags_and_fill(X, cat_cols)\nX_test = add_missing_flags_and_fill(X_test, cat_cols)\n\n# 4) rare grouping\nX, X_test = group_rare_categories(X, X_test, cat_cols, min_count=RARE_MIN_COUNT)\n\n# 5) freq encodings\nX, X_test = add_freq_enc(X, X_test, cat_cols)\n\n# 6) numeric bins + transforms + interactions\nX, X_test = add_numeric_bins(X, X_test, num_cols, n_bins=N_BINS)\nX, X_test = add_numeric_transforms(X, X_test, num_cols)\n\n# 7) hashed crosses (пара штук)\nX, X_test = add_hashed_crosses(X, X_test, cat_cols, max_pairs=MAX_HASHED_CROSSES)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:01:14.161933Z","iopub.execute_input":"2025-12-15T20:01:14.162180Z","iopub.status.idle":"2025-12-15T20:02:40.840458Z","shell.execute_reply.started":"2025-12-15T20:01:14.162155Z","shell.execute_reply":"2025-12-15T20:02:40.839847Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def train_base_model(X, y, X_test, model_name, params={}, n_splits=N_SPLITS, save_dir=\"models\"):\n    os.makedirs(save_dir, exist_ok=True)\n    \n    oof = np.zeros((X.shape[0], 2))\n    test_pred = np.zeros((X_test.shape[0], 2))\n\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n\n        y_tr_smooth = y_tr\n\n        model = None\n\n        if model_name == \"CatBoost\":\n            pool_tr = Pool(X_tr, y_tr_smooth, cat_features=cat_cols)\n            pool_val = Pool(X_val, y_val, cat_features=cat_cols)\n            model = CatBoostClassifier(\n                iterations=10000,\n                learning_rate=0.05,\n                depth=8,\n                task_type=\"GPU\" if USE_GPU else \"CPU\",\n                loss_function=\"Logloss\",\n                **params,\n                verbose=500\n            )\n            model.fit(pool_tr, eval_set=pool_val, early_stopping_rounds=100)\n            oof[val_idx] = model.predict_proba(X_val)\n            test_pred += model.predict_proba(X_test) / n_splits\n\n            # Сохраняем модель\n            model.save_model(os.path.join(save_dir, f\"catboost_fold{fold+1}.cbm\"))\n\n        elif model_name == \"LightGBM\":\n            X_tr_lgb = cast_categoricals_for_lgb(X_tr, cat_cols)\n            X_val_lgb = cast_categoricals_for_lgb(X_val, cat_cols)\n            X_test_lgb = cast_categoricals_for_lgb(X_test, cat_cols)\n        \n            dtrain = lgb.Dataset(\n                X_tr_lgb,\n                label=y_tr_smooth,\n                categorical_feature=cat_cols\n            )\n            dval = lgb.Dataset(\n                X_val_lgb,\n                label=y_val,\n                categorical_feature=cat_cols,\n                reference=dtrain\n            )\n        \n            model = lgb.train(\n                params,\n                dtrain,\n                num_boost_round=10000,\n                valid_sets=[dtrain, dval],\n                callbacks=[\n                    lgb.early_stopping(stopping_rounds=100),\n                    lgb.log_evaluation(period=500)\n                ]\n            )     \n            val_pred_1 = model.predict(X_val_lgb)\n            val_pred_0 = 1.0 - val_pred_1\n            oof[val_idx] = np.column_stack([val_pred_0, val_pred_1])\n            \n            test_pred_1 = model.predict(X_test_lgb)\n            test_pred_0 = 1.0 - test_pred_1\n            test_pred += np.column_stack([test_pred_0, test_pred_1]) / n_splits\n\n            # Сохраняем модель\n            model.save_model(os.path.join(save_dir, f\"lgb_fold{fold+1}.txt\"))\n\n        elif model_name == \"XGBoost\":\n            X_tr_xgb   = cast_categoricals_for_lgb(X_tr, cat_cols)\n            X_val_xgb  = cast_categoricals_for_lgb(X_val, cat_cols)\n            X_test_xgb = cast_categoricals_for_lgb(X_test, cat_cols)\n        \n            dtrain = xgb.DMatrix(X_tr_xgb, label=y_tr_smooth, enable_categorical=True)\n            dval   = xgb.DMatrix(X_val_xgb, label=y_val, enable_categorical=True)\n            dtest  = xgb.DMatrix(X_test_xgb, enable_categorical=True)\n        \n            model = xgb.train(\n                params,\n                dtrain,\n                num_boost_round=10000,\n                evals=[(dtrain, \"train\"), (dval, \"valid\")],\n                early_stopping_rounds=100,\n                verbose_eval=500\n            )\n        \n            val_pred_1 = model.predict(dval)\n            oof[val_idx] = np.column_stack([1 - val_pred_1, val_pred_1])\n        \n            test_pred_1 = model.predict(dtest)\n            test_pred += np.column_stack([1 - test_pred_1, test_pred_1]) / n_splits\n\n            # Сохраняем модель\n            model.save_model(os.path.join(save_dir, f\"xgb_fold{fold+1}.json\"))\n\n        score = matthews_corrcoef(y_val, (oof[val_idx][:,1]>=0.5).astype(int))\n        print(f\"{model_name} fold {fold+1} MCC: {score:.6f}\")\n\n        del X_tr, X_val, y_tr, y_val, model\n        gc.collect()\n\n    return oof, test_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:03:46.272227Z","iopub.execute_input":"2025-12-15T20:03:46.272954Z","iopub.status.idle":"2025-12-15T20:03:46.285014Z","shell.execute_reply.started":"2025-12-15T20:03:46.272932Z","shell.execute_reply":"2025-12-15T20:03:46.284471Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def cast_categoricals_for_lgb(df, cat_cols):\n    df = df.copy()\n    for c in cat_cols:\n        df[c] = df[c].astype(\"category\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:03:55.968144Z","iopub.execute_input":"2025-12-15T20:03:55.968819Z","iopub.status.idle":"2025-12-15T20:03:55.972575Z","shell.execute_reply.started":"2025-12-15T20:03:55.968794Z","shell.execute_reply":"2025-12-15T20:03:55.971913Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nmodel_names = [\"XGBoost\", \"LightGBM\", \"CatBoost\"]\noof_pred_probs = {}\ntest_pred_probs = {}\nfor mname in model_names:\n    print(f\"\\n=== Training {mname} ===\")\n    oof_pred_probs[mname], test_pred_probs[mname] = train_base_model(X, y, X_test, mname)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:03:59.009994Z","iopub.execute_input":"2025-12-15T20:03:59.010687Z","iopub.status.idle":"2025-12-16T03:59:57.959229Z","shell.execute_reply.started":"2025-12-15T20:03:59.010664Z","shell.execute_reply":"2025-12-16T03:59:57.958295Z"}},"outputs":[{"name":"stdout","text":"\n=== Training XGBoost ===\n[0]\ttrain-rmse:0.40316\tvalid-rmse:0.40341\n[500]\ttrain-rmse:0.08747\tvalid-rmse:0.09195\n[1000]\ttrain-rmse:0.08255\tvalid-rmse:0.09007\n[1500]\ttrain-rmse:0.07954\tvalid-rmse:0.08941\n[2000]\ttrain-rmse:0.07724\tvalid-rmse:0.08928\n[2373]\ttrain-rmse:0.07582\tvalid-rmse:0.08922\nXGBoost fold 1 MCC: 0.983690\n[0]\ttrain-rmse:0.40329\tvalid-rmse:0.40319\n[500]\ttrain-rmse:0.08738\tvalid-rmse:0.09168\n[1000]\ttrain-rmse:0.08259\tvalid-rmse:0.08978\n[1500]\ttrain-rmse:0.07962\tvalid-rmse:0.08926\n[2000]\ttrain-rmse:0.07734\tvalid-rmse:0.08909\n[2151]\ttrain-rmse:0.07673\tvalid-rmse:0.08911\nXGBoost fold 2 MCC: 0.983682\n[0]\ttrain-rmse:0.40328\tvalid-rmse:0.40315\n[500]\ttrain-rmse:0.08776\tvalid-rmse:0.09189\n[1000]\ttrain-rmse:0.08286\tvalid-rmse:0.08991\n[1500]\ttrain-rmse:0.07982\tvalid-rmse:0.08934\n[2000]\ttrain-rmse:0.07747\tvalid-rmse:0.08918\n[2409]\ttrain-rmse:0.07584\tvalid-rmse:0.08908\nXGBoost fold 3 MCC: 0.983875\n[0]\ttrain-rmse:0.40323\tvalid-rmse:0.40328\n[500]\ttrain-rmse:0.08716\tvalid-rmse:0.09194\n[1000]\ttrain-rmse:0.08228\tvalid-rmse:0.08997\n[1500]\ttrain-rmse:0.07935\tvalid-rmse:0.08940\n[1881]\ttrain-rmse:0.07754\tvalid-rmse:0.08931\nXGBoost fold 4 MCC: 0.983721\n[0]\ttrain-rmse:0.40321\tvalid-rmse:0.40325\n[500]\ttrain-rmse:0.08748\tvalid-rmse:0.09188\n[1000]\ttrain-rmse:0.08255\tvalid-rmse:0.08992\n[1500]\ttrain-rmse:0.07961\tvalid-rmse:0.08939\n[2000]\ttrain-rmse:0.07726\tvalid-rmse:0.08922\n[2393]\ttrain-rmse:0.07576\tvalid-rmse:0.08917\nXGBoost fold 5 MCC: 0.983694\n\n=== Training LightGBM ===\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.589704 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3238\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 103\n[LightGBM] [Info] Start training from score 0.547137\nTraining until validation scores don't improve for 100 rounds\n[500]\ttraining's l2: 0.00901631\tvalid_1's l2: 0.00921967\n[1000]\ttraining's l2: 0.00803872\tvalid_1's l2: 0.00843155\n[1500]\ttraining's l2: 0.00757548\tvalid_1's l2: 0.00812712\n[2000]\ttraining's l2: 0.00727031\tvalid_1's l2: 0.00795022\n[2500]\ttraining's l2: 0.00704209\tvalid_1's l2: 0.0078469\n[3000]\ttraining's l2: 0.0068656\tvalid_1's l2: 0.00778016\n[3500]\ttraining's l2: 0.00671181\tvalid_1's l2: 0.00772427\n[4000]\ttraining's l2: 0.00657275\tvalid_1's l2: 0.00768263\n[4500]\ttraining's l2: 0.00645603\tvalid_1's l2: 0.0076529\n[5000]\ttraining's l2: 0.00634434\tvalid_1's l2: 0.00762814\n[5500]\ttraining's l2: 0.00624107\tvalid_1's l2: 0.00760601\n[6000]\ttraining's l2: 0.00613936\tvalid_1's l2: 0.00758549\n[6500]\ttraining's l2: 0.00605245\tvalid_1's l2: 0.00757333\n[7000]\ttraining's l2: 0.00597126\tvalid_1's l2: 0.00756513\n[7500]\ttraining's l2: 0.00589339\tvalid_1's l2: 0.00755893\n[8000]\ttraining's l2: 0.00582016\tvalid_1's l2: 0.00755377\nEarly stopping, best iteration is:\n[8306]\ttraining's l2: 0.00577931\tvalid_1's l2: 0.00755188\nLightGBM fold 1 MCC: 0.984354\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.600848 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3245\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 105\n[LightGBM] [Info] Start training from score 0.547137\nTraining until validation scores don't improve for 100 rounds\n[500]\ttraining's l2: 0.00903861\tvalid_1's l2: 0.00924595\n[1000]\ttraining's l2: 0.00809924\tvalid_1's l2: 0.00849313\n[1500]\ttraining's l2: 0.00763392\tvalid_1's l2: 0.00818728\n[2000]\ttraining's l2: 0.00732006\tvalid_1's l2: 0.00800671\n[2500]\ttraining's l2: 0.00708181\tvalid_1's l2: 0.00789836\n[3000]\ttraining's l2: 0.0068884\tvalid_1's l2: 0.00781894\n[3500]\ttraining's l2: 0.00673356\tvalid_1's l2: 0.00777129\n[4000]\ttraining's l2: 0.00659104\tvalid_1's l2: 0.00772728\n[4500]\ttraining's l2: 0.00646399\tvalid_1's l2: 0.00769415\n[5000]\ttraining's l2: 0.00635481\tvalid_1's l2: 0.00767149\n[5500]\ttraining's l2: 0.00625251\tvalid_1's l2: 0.00765261\n[6000]\ttraining's l2: 0.00615536\tvalid_1's l2: 0.00763468\n[6500]\ttraining's l2: 0.00606508\tvalid_1's l2: 0.00762388\n[7000]\ttraining's l2: 0.00598022\tvalid_1's l2: 0.00761146\nEarly stopping, best iteration is:\n[7068]\ttraining's l2: 0.00597023\tvalid_1's l2: 0.00761084\nLightGBM fold 2 MCC: 0.984203\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.611664 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3257\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 105\n[LightGBM] [Info] Start training from score 0.547137\nTraining until validation scores don't improve for 100 rounds\n[500]\ttraining's l2: 0.00907982\tvalid_1's l2: 0.00922584\n[1000]\ttraining's l2: 0.0081019\tvalid_1's l2: 0.00844069\n[1500]\ttraining's l2: 0.00762868\tvalid_1's l2: 0.00812705\n[2000]\ttraining's l2: 0.00731721\tvalid_1's l2: 0.00795951\n[2500]\ttraining's l2: 0.0070821\tvalid_1's l2: 0.00785042\n[3000]\ttraining's l2: 0.00689697\tvalid_1's l2: 0.00777633\n[3500]\ttraining's l2: 0.00673724\tvalid_1's l2: 0.00772274\n[4000]\ttraining's l2: 0.00659804\tvalid_1's l2: 0.00767946\n[4500]\ttraining's l2: 0.00646902\tvalid_1's l2: 0.00764797\n[5000]\ttraining's l2: 0.00635786\tvalid_1's l2: 0.00762192\n[5500]\ttraining's l2: 0.00625579\tvalid_1's l2: 0.00760706\n[6000]\ttraining's l2: 0.00616516\tvalid_1's l2: 0.00759626\n[6500]\ttraining's l2: 0.00607934\tvalid_1's l2: 0.00758547\n[7000]\ttraining's l2: 0.00599632\tvalid_1's l2: 0.00757542\n[7500]\ttraining's l2: 0.00592025\tvalid_1's l2: 0.00756596\n[8000]\ttraining's l2: 0.00584071\tvalid_1's l2: 0.00755606\n[8500]\ttraining's l2: 0.00576755\tvalid_1's l2: 0.0075503\nEarly stopping, best iteration is:\n[8460]\ttraining's l2: 0.00577235\tvalid_1's l2: 0.00754983\nLightGBM fold 3 MCC: 0.984380\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.605164 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3239\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 103\n[LightGBM] [Info] Start training from score 0.547137\nTraining until validation scores don't improve for 100 rounds\n[500]\ttraining's l2: 0.00902769\tvalid_1's l2: 0.00930358\n[1000]\ttraining's l2: 0.00806014\tvalid_1's l2: 0.00851366\n[1500]\ttraining's l2: 0.00759242\tvalid_1's l2: 0.00819999\n[2000]\ttraining's l2: 0.007271\tvalid_1's l2: 0.0080172\n[2500]\ttraining's l2: 0.00704387\tvalid_1's l2: 0.00791279\n[3000]\ttraining's l2: 0.00686637\tvalid_1's l2: 0.00784579\n[3500]\ttraining's l2: 0.00670735\tvalid_1's l2: 0.00779176\n[4000]\ttraining's l2: 0.00657709\tvalid_1's l2: 0.00775685\n[4500]\ttraining's l2: 0.00645604\tvalid_1's l2: 0.00772757\n[5000]\ttraining's l2: 0.00634908\tvalid_1's l2: 0.00770701\n[5500]\ttraining's l2: 0.00625025\tvalid_1's l2: 0.00768818\n[6000]\ttraining's l2: 0.00615278\tvalid_1's l2: 0.00767479\n[6500]\ttraining's l2: 0.00606445\tvalid_1's l2: 0.00766363\n[7000]\ttraining's l2: 0.00598179\tvalid_1's l2: 0.00765259\n[7500]\ttraining's l2: 0.00590694\tvalid_1's l2: 0.00764654\n[8000]\ttraining's l2: 0.00583175\tvalid_1's l2: 0.00763797\n[8500]\ttraining's l2: 0.00575302\tvalid_1's l2: 0.00762997\nEarly stopping, best iteration is:\n[8576]\ttraining's l2: 0.0057428\tvalid_1's l2: 0.00762861\nLightGBM fold 4 MCC: 0.984119\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.588178 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3241\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 102\n[LightGBM] [Info] Start training from score 0.547137\nTraining until validation scores don't improve for 100 rounds\n[500]\ttraining's l2: 0.00905391\tvalid_1's l2: 0.00922768\n[1000]\ttraining's l2: 0.00804748\tvalid_1's l2: 0.00840265\n[1500]\ttraining's l2: 0.0075862\tvalid_1's l2: 0.00809528\n[2000]\ttraining's l2: 0.0072837\tvalid_1's l2: 0.00793162\n[2500]\ttraining's l2: 0.00707005\tvalid_1's l2: 0.00783866\n[3000]\ttraining's l2: 0.00687577\tvalid_1's l2: 0.00776138\n[3500]\ttraining's l2: 0.00670724\tvalid_1's l2: 0.00770302\n[4000]\ttraining's l2: 0.00656356\tvalid_1's l2: 0.00766251\n[4500]\ttraining's l2: 0.00644347\tvalid_1's l2: 0.00763672\n[5000]\ttraining's l2: 0.00633467\tvalid_1's l2: 0.00761659\n[5500]\ttraining's l2: 0.00622686\tvalid_1's l2: 0.00759693\n[6000]\ttraining's l2: 0.00613798\tvalid_1's l2: 0.00758476\n[6500]\ttraining's l2: 0.00605085\tvalid_1's l2: 0.00757463\n[7000]\ttraining's l2: 0.00597416\tvalid_1's l2: 0.00756837\n[7500]\ttraining's l2: 0.00590131\tvalid_1's l2: 0.00756219\n[8000]\ttraining's l2: 0.00582566\tvalid_1's l2: 0.00755716\nEarly stopping, best iteration is:\n[7936]\ttraining's l2: 0.00583516\tvalid_1's l2: 0.00755693\nLightGBM fold 5 MCC: 0.984312\n\n=== Training CatBoost ===\n0:\tlearn: 0.6413623\ttest: 0.6413379\tbest: 0.6413379 (0)\ttotal: 6.84s\tremaining: 19h 45s\n500:\tlearn: 0.0377336\ttest: 0.0383544\tbest: 0.0383544 (500)\ttotal: 3m 26s\tremaining: 1h 5m 15s\n1000:\tlearn: 0.0364650\ttest: 0.0374849\tbest: 0.0374849 (1000)\ttotal: 6m 39s\tremaining: 59m 54s\n1500:\tlearn: 0.0356872\ttest: 0.0370572\tbest: 0.0370572 (1500)\ttotal: 9m 53s\tremaining: 55m 59s\n2000:\tlearn: 0.0350560\ttest: 0.0367933\tbest: 0.0367931 (1999)\ttotal: 13m 8s\tremaining: 52m 31s\n2500:\tlearn: 0.0345083\ttest: 0.0366200\tbest: 0.0366198 (2498)\ttotal: 16m 27s\tremaining: 49m 20s\n3000:\tlearn: 0.0340114\ttest: 0.0364985\tbest: 0.0364981 (2997)\ttotal: 19m 47s\tremaining: 46m 9s\n3500:\tlearn: 0.0335747\ttest: 0.0364059\tbest: 0.0364059 (3500)\ttotal: 23m 5s\tremaining: 42m 52s\n4000:\tlearn: 0.0331540\ttest: 0.0363338\tbest: 0.0363338 (4000)\ttotal: 26m 25s\tremaining: 39m 37s\n4500:\tlearn: 0.0327548\ttest: 0.0362786\tbest: 0.0362786 (4500)\ttotal: 29m 47s\tremaining: 36m 23s\n5000:\tlearn: 0.0323766\ttest: 0.0362391\tbest: 0.0362391 (5000)\ttotal: 33m 10s\tremaining: 33m 9s\n5500:\tlearn: 0.0320276\ttest: 0.0362125\tbest: 0.0362120 (5497)\ttotal: 36m 34s\tremaining: 29m 54s\n6000:\tlearn: 0.0316891\ttest: 0.0361963\tbest: 0.0361911 (5933)\ttotal: 39m 59s\tremaining: 26m 38s\nbestTest = 0.03619107988\nbestIteration = 5933\nShrink model to first 5934 iterations.\nCatBoost fold 1 MCC: 0.984594\n0:\tlearn: 0.6437711\ttest: 0.6436151\tbest: 0.6436151 (0)\ttotal: 449ms\tremaining: 1h 14m 52s\n500:\tlearn: 0.0376118\ttest: 0.0382805\tbest: 0.0382805 (500)\ttotal: 3m 19s\tremaining: 1h 3m\n1000:\tlearn: 0.0364098\ttest: 0.0374893\tbest: 0.0374893 (1000)\ttotal: 6m 33s\tremaining: 58m 55s\n1500:\tlearn: 0.0356063\ttest: 0.0370899\tbest: 0.0370899 (1500)\ttotal: 9m 50s\tremaining: 55m 41s\n2000:\tlearn: 0.0349769\ttest: 0.0368505\tbest: 0.0368505 (2000)\ttotal: 13m 6s\tremaining: 52m 25s\n2500:\tlearn: 0.0344522\ttest: 0.0366975\tbest: 0.0366974 (2499)\ttotal: 16m 25s\tremaining: 49m 14s\n3000:\tlearn: 0.0339772\ttest: 0.0365813\tbest: 0.0365813 (3000)\ttotal: 19m 44s\tremaining: 46m 3s\n3500:\tlearn: 0.0335294\ttest: 0.0364988\tbest: 0.0364984 (3496)\ttotal: 23m 5s\tremaining: 42m 52s\n4000:\tlearn: 0.0331135\ttest: 0.0364360\tbest: 0.0364360 (4000)\ttotal: 26m 29s\tremaining: 39m 43s\n4500:\tlearn: 0.0327142\ttest: 0.0363648\tbest: 0.0363646 (4499)\ttotal: 29m 53s\tremaining: 36m 31s\n5000:\tlearn: 0.0323428\ttest: 0.0363341\tbest: 0.0363341 (5000)\ttotal: 33m 21s\tremaining: 33m 20s\n5500:\tlearn: 0.0319969\ttest: 0.0363018\tbest: 0.0363017 (5482)\ttotal: 36m 48s\tremaining: 30m 6s\n6000:\tlearn: 0.0316283\ttest: 0.0362827\tbest: 0.0362811 (5994)\ttotal: 40m 17s\tremaining: 26m 51s\nbestTest = 0.03628113388\nbestIteration = 5994\nShrink model to first 5995 iterations.\nCatBoost fold 2 MCC: 0.984477\n0:\tlearn: 0.6413667\ttest: 0.6413033\tbest: 0.6413033 (0)\ttotal: 452ms\tremaining: 1h 15m 19s\n500:\tlearn: 0.0376026\ttest: 0.0381446\tbest: 0.0381446 (500)\ttotal: 3m 19s\tremaining: 1h 3m 9s\n1000:\tlearn: 0.0364263\ttest: 0.0373787\tbest: 0.0373787 (1000)\ttotal: 6m 35s\tremaining: 59m 16s\n1500:\tlearn: 0.0356725\ttest: 0.0369962\tbest: 0.0369962 (1500)\ttotal: 9m 52s\tremaining: 55m 57s\n2000:\tlearn: 0.0350643\ttest: 0.0367744\tbest: 0.0367744 (2000)\ttotal: 13m 12s\tremaining: 52m 49s\n2500:\tlearn: 0.0345222\ttest: 0.0366038\tbest: 0.0366037 (2499)\ttotal: 16m 33s\tremaining: 49m 39s\n3000:\tlearn: 0.0340354\ttest: 0.0364676\tbest: 0.0364676 (3000)\ttotal: 19m 54s\tremaining: 46m 25s\n3500:\tlearn: 0.0335915\ttest: 0.0363725\tbest: 0.0363725 (3500)\ttotal: 23m 17s\tremaining: 43m 14s\n4000:\tlearn: 0.0331960\ttest: 0.0362951\tbest: 0.0362950 (3999)\ttotal: 26m 39s\tremaining: 39m 58s\n4500:\tlearn: 0.0328464\ttest: 0.0362472\tbest: 0.0362472 (4500)\ttotal: 30m 5s\tremaining: 36m 45s\n5000:\tlearn: 0.0324931\ttest: 0.0362052\tbest: 0.0362051 (4999)\ttotal: 33m 30s\tremaining: 33m 29s\n5500:\tlearn: 0.0321456\ttest: 0.0361754\tbest: 0.0361753 (5476)\ttotal: 36m 55s\tremaining: 30m 12s\n6000:\tlearn: 0.0318161\ttest: 0.0361439\tbest: 0.0361436 (5991)\ttotal: 40m 22s\tremaining: 26m 54s\nbestTest = 0.03613183341\nbestIteration = 6236\nShrink model to first 6237 iterations.\nCatBoost fold 3 MCC: 0.984630\n0:\tlearn: 0.6415157\ttest: 0.6415986\tbest: 0.6415986 (0)\ttotal: 446ms\tremaining: 1h 14m 22s\n500:\tlearn: 0.0377263\ttest: 0.0386593\tbest: 0.0386593 (500)\ttotal: 3m 19s\tremaining: 1h 2m 59s\n1000:\tlearn: 0.0364368\ttest: 0.0377841\tbest: 0.0377841 (1000)\ttotal: 6m 33s\tremaining: 59m 1s\n1500:\tlearn: 0.0356048\ttest: 0.0373587\tbest: 0.0373587 (1500)\ttotal: 9m 49s\tremaining: 55m 40s\n2000:\tlearn: 0.0349690\ttest: 0.0371162\tbest: 0.0371162 (2000)\ttotal: 13m 8s\tremaining: 52m 32s\n2500:\tlearn: 0.0344351\ttest: 0.0369521\tbest: 0.0369521 (2497)\ttotal: 16m 27s\tremaining: 49m 19s\n3000:\tlearn: 0.0339493\ttest: 0.0368294\tbest: 0.0368294 (3000)\ttotal: 19m 47s\tremaining: 46m 9s\n3500:\tlearn: 0.0335023\ttest: 0.0367463\tbest: 0.0367463 (3500)\ttotal: 23m 8s\tremaining: 42m 58s\n4000:\tlearn: 0.0330834\ttest: 0.0366678\tbest: 0.0366673 (3998)\ttotal: 26m 28s\tremaining: 39m 41s\n4500:\tlearn: 0.0326917\ttest: 0.0366120\tbest: 0.0366117 (4495)\ttotal: 29m 52s\tremaining: 36m 29s\n5000:\tlearn: 0.0323241\ttest: 0.0365660\tbest: 0.0365660 (5000)\ttotal: 33m 14s\tremaining: 33m 13s\n5500:\tlearn: 0.0319665\ttest: 0.0365445\tbest: 0.0365437 (5479)\ttotal: 36m 37s\tremaining: 29m 56s\n6000:\tlearn: 0.0316071\ttest: 0.0365225\tbest: 0.0365225 (5999)\ttotal: 40m 3s\tremaining: 26m 41s\nbestTest = 0.03651521537\nbestIteration = 6121\nShrink model to first 6122 iterations.\nCatBoost fold 4 MCC: 0.984316\n0:\tlearn: 0.6417971\ttest: 0.6417742\tbest: 0.6417742 (0)\ttotal: 449ms\tremaining: 1h 14m 51s\n500:\tlearn: 0.0378063\ttest: 0.0382956\tbest: 0.0382956 (500)\ttotal: 3m 18s\tremaining: 1h 2m 40s\n1000:\tlearn: 0.0365310\ttest: 0.0374827\tbest: 0.0374827 (1000)\ttotal: 6m 32s\tremaining: 58m 44s\n1500:\tlearn: 0.0357261\ttest: 0.0370984\tbest: 0.0370984 (1500)\ttotal: 9m 47s\tremaining: 55m 27s\n2000:\tlearn: 0.0350661\ttest: 0.0368458\tbest: 0.0368458 (2000)\ttotal: 13m 4s\tremaining: 52m 14s\n2500:\tlearn: 0.0345238\ttest: 0.0366796\tbest: 0.0366796 (2498)\ttotal: 16m 22s\tremaining: 49m 5s\n3000:\tlearn: 0.0340438\ttest: 0.0365718\tbest: 0.0365714 (2999)\ttotal: 19m 43s\tremaining: 46m 1s\n3500:\tlearn: 0.0336005\ttest: 0.0364909\tbest: 0.0364908 (3496)\ttotal: 23m 5s\tremaining: 42m 52s\n4000:\tlearn: 0.0331955\ttest: 0.0364278\tbest: 0.0364278 (3994)\ttotal: 26m 28s\tremaining: 39m 42s\n4500:\tlearn: 0.0328156\ttest: 0.0363790\tbest: 0.0363790 (4500)\ttotal: 29m 50s\tremaining: 36m 28s\n5000:\tlearn: 0.0324457\ttest: 0.0363283\tbest: 0.0363283 (5000)\ttotal: 33m 16s\tremaining: 33m 15s\n5500:\tlearn: 0.0320936\ttest: 0.0362921\tbest: 0.0362914 (5458)\ttotal: 36m 39s\tremaining: 29m 59s\n6000:\tlearn: 0.0317444\ttest: 0.0362678\tbest: 0.0362676 (5992)\ttotal: 40m 7s\tremaining: 26m 44s\nbestTest = 0.03626700997\nbestIteration = 6061\nShrink model to first 6062 iterations.\nCatBoost fold 5 MCC: 0.984532\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"X_stack = np.column_stack(list(oof_pred_probs.values())).clip(1e-15, 1 - 1e-15)\nX_test_stack = np.column_stack(list(test_pred_probs.values())).clip(1e-15, 1 - 1e-15)\n\nstack_model = make_pipeline(\n    FunctionTransformer(scipy.special.logit),\n    LogisticRegression(\n        max_iter=10000,\n        penalty=None,\n        class_weight=\"balanced\"\n    )\n)\n\n# skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\n# oof_stack = np.zeros((X_stack.shape[0], 2))\n# test_stack = np.zeros((X_test_stack.shape[0], 2))\n\n# for fold, (tr_idx, val_idx) in enumerate(skf.split(X_stack, y)):\n#     X_tr, X_val = X_stack[tr_idx], X_stack[val_idx]\n#     y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n\n#     stack_model.fit(X_tr, y_tr)\n\n#     oof_stack[val_idx] = stack_model.predict_proba(X_val)\n#     test_stack += stack_model.predict_proba(X_test_stack) / N_SPLITS\n\n#     fold_mcc = matthews_corrcoef(\n#         y_val,\n#         (oof_stack[val_idx][:, 1] >= THRESHOLD).astype(int)\n#     )\n#     print(f\"Stack fold {fold+1} MCC: {fold_mcc:.6f}\")\n\nstack_model.fit(X_stack, y)\n\noof_stack = stack_model.predict_proba(X_stack)\ntest_stack = stack_model.predict_proba(X_test_stack)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:45:24.346591Z","iopub.execute_input":"2025-12-16T04:45:24.347247Z","iopub.status.idle":"2025-12-16T04:45:30.851492Z","shell.execute_reply.started":"2025-12-16T04:45:24.347224Z","shell.execute_reply":"2025-12-16T04:45:30.850666Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from sklearn.metrics import matthews_corrcoef\n\nbest_thr = 0.5\nbest_mcc = -1\n\nfor thr in np.linspace(0.2, 0.8, 301):\n    mcc = matthews_corrcoef(y, (oof_stack[:,1] >= thr).astype(int))\n    if mcc > best_mcc:\n        best_mcc = mcc\n        best_thr = thr\n\nprint(f\"Best threshold = {best_thr:.4f}, MCC = {best_mcc:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:45:30.852843Z","iopub.execute_input":"2025-12-16T04:45:30.853118Z","iopub.status.idle":"2025-12-16T04:47:25.667556Z","shell.execute_reply.started":"2025-12-16T04:45:30.853095Z","shell.execute_reply":"2025-12-16T04:47:25.666719Z"}},"outputs":[{"name":"stdout","text":"Best threshold = 0.4580, MCC = 0.984515\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"test_proba = test_stack[:, 1]\ntest_pred  = np.where(test_proba >= best_thr, \"p\", \"e\")\n\ntest_ids = test[\"id\"].values\n\nsubmission = pd.DataFrame({\n    \"id\": test_ids,\n    \"class\": test_pred\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:47:25.668727Z","iopub.execute_input":"2025-12-16T04:47:25.669031Z","iopub.status.idle":"2025-12-16T04:47:27.075085Z","shell.execute_reply.started":"2025-12-16T04:47:25.669014Z","shell.execute_reply":"2025-12-16T04:47:27.074290Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"!pip install kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:44:45.655100Z","iopub.execute_input":"2025-12-15T19:44:45.656045Z","iopub.status.idle":"2025-12-15T19:44:50.101910Z","shell.execute_reply.started":"2025-12-15T19:44:45.656008Z","shell.execute_reply":"2025-12-15T19:44:50.101121Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.10.5)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.4)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.11)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.33.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.5)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.5.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import json\n\nos.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n\nkaggle_json = {\n    \"username\": \"aleks9921\",\n    \"key\": \"85a9b540183c46bec0906f4b4be20819\"\n}\n\n# Сохраняем\nwith open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n    json.dump(kaggle_json, f)\n\n# Устанавливаем права доступа\nos.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:07:54.494865Z","iopub.execute_input":"2025-12-16T04:07:54.495564Z","iopub.status.idle":"2025-12-16T04:07:54.500169Z","shell.execute_reply.started":"2025-12-16T04:07:54.495542Z","shell.execute_reply":"2025-12-16T04:07:54.499650Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"!kaggle competitions list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:52:23.283606Z","iopub.execute_input":"2025-12-15T19:52:23.284284Z","iopub.status.idle":"2025-12-15T19:52:24.091348Z","shell.execute_reply.started":"2025-12-15T19:52:23.284262Z","shell.execute_reply":"2025-12-15T19:52:24.090616Z"}},"outputs":[{"name":"stdout","text":"ref                                                                                 deadline             category                reward  teamCount  userHasEntered  \n----------------------------------------------------------------------------------  -------------------  ---------------  -------------  ---------  --------------  \nhttps://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3       2026-04-15 23:59:00  Featured         2,207,152 Usd        784           False  \nhttps://www.kaggle.com/competitions/vesuvius-challenge-surface-detection            2026-02-13 23:59:00  Research           200,000 Usd        344           False  \nhttps://www.kaggle.com/competitions/hull-tactical-market-prediction                 2025-12-15 23:59:00  Featured           100,000 Usd       3688           False  \nhttps://www.kaggle.com/competitions/google-tunix-hackathon                          2026-01-12 23:59:00  Featured           100,000 Usd         82           False  \nhttps://www.kaggle.com/competitions/csiro-biomass                                   2026-01-28 23:59:00  Research            75,000 Usd       2053           False  \nhttps://www.kaggle.com/competitions/recodai-luc-scientific-image-forgery-detection  2026-01-15 23:59:00  Research            55,000 Usd        839           False  \nhttps://www.kaggle.com/competitions/santa-2025                                      2026-01-30 23:59:00  Featured            50,000 Usd       1709           False  \nhttps://www.kaggle.com/competitions/MABe-mouse-behavior-detection                   2025-12-15 23:59:00  Research            50,000 Usd       1451           False  \nhttps://www.kaggle.com/competitions/cafa-6-protein-function-prediction              2026-02-02 23:59:00  Research            50,000 Usd       1142           False  \nhttps://www.kaggle.com/competitions/physionet-ecg-image-digitization                2026-01-22 23:59:00  Research            50,000 Usd        720           False  \nhttps://www.kaggle.com/competitions/nfl-big-data-bowl-2026-analytics                2025-12-17 23:59:00  Featured            50,000 Usd        113           False  \nhttps://www.kaggle.com/competitions/playground-series-s5e12                         2025-12-31 23:59:00  Playground                Swag       2048           False  \nhttps://www.kaggle.com/competitions/titanic                                         2030-01-01 00:00:00  Getting Started      Knowledge      16241           False  \nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques     2030-01-01 00:00:00  Getting Started      Knowledge       6036           False  \nhttps://www.kaggle.com/competitions/home-data-for-ml-course                         2030-01-01 23:59:00  Getting Started      Knowledge       5023           False  \nhttps://www.kaggle.com/competitions/spaceship-titanic                               2030-01-01 00:00:00  Getting Started      Knowledge       2579           False  \nhttps://www.kaggle.com/competitions/digit-recognizer                                2030-01-01 00:00:00  Getting Started      Knowledge       1506           False  \nhttps://www.kaggle.com/competitions/nlp-getting-started                             2030-01-01 00:00:00  Getting Started      Knowledge        765           False  \nhttps://www.kaggle.com/competitions/store-sales-time-series-forecasting             2030-06-30 23:59:00  Getting Started      Knowledge        643           False  \nhttps://www.kaggle.com/competitions/tpu-getting-started                             2030-06-03 23:59:00  Getting Started      Knowledge        302           False  \n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"no kfold\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:51:45.676494Z","iopub.execute_input":"2025-12-16T04:51:45.677205Z","iopub.status.idle":"2025-12-16T04:51:49.399273Z","shell.execute_reply.started":"2025-12-16T04:51:45.677182Z","shell.execute_reply":"2025-12-16T04:51:49.398552Z"}},"outputs":[{"name":"stdout","text":"100%|██████████████████████████████████████| 19.8M/19.8M [00:01<00:00, 12.2MB/s]\nSuccessfully submitted to Binary Prediction of Poisonous Mushrooms","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"g = pd.read_csv(\"submission.csv\")\ng","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:33:57.595390Z","iopub.execute_input":"2025-12-15T19:33:57.595623Z","iopub.status.idle":"2025-12-15T19:33:57.823919Z","shell.execute_reply.started":"2025-12-15T19:33:57.595607Z","shell.execute_reply":"2025-12-15T19:33:57.823115Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"              id  class\n0        3116945      0\n1        3116946      1\n2        3116947      1\n3        3116948      1\n4        3116949      0\n...          ...    ...\n2077959  5194904      1\n2077960  5194905      1\n2077961  5194906      1\n2077962  5194907      0\n2077963  5194908      0\n\n[2077964 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3116945</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3116946</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3116947</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3116948</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3116949</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2077959</th>\n      <td>5194904</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2077960</th>\n      <td>5194905</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2077961</th>\n      <td>5194906</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2077962</th>\n      <td>5194907</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2077963</th>\n      <td>5194908</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2077964 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:34:05.147118Z","iopub.execute_input":"2025-12-15T19:34:05.147782Z","iopub.status.idle":"2025-12-15T19:34:05.154509Z","shell.execute_reply.started":"2025-12-15T19:34:05.147755Z","shell.execute_reply":"2025-12-15T19:34:05.153720Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"        id  class\n0  3116945      0\n1  3116946      1\n2  3116947      1\n3  3116948      1\n4  3116949      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3116945</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3116946</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3116947</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3116948</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3116949</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31}]}